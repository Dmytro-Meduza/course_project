{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Imports and settings"
      ],
      "metadata": {
        "id": "vL1j7dl15C3p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32ADSu9y4kxc"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access DIV2K dataset\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths to dataset\n",
        "DIV2K_DIR = \"/content/drive/My Drive/DIV2K\"\n",
        "DIV2K_train_HR = os.path.join(DIV2K_DIR, \"DIV2K_train_HR\")\n",
        "DIV2K_valid_HR = os.path.join(DIV2K_DIR, \"DIV2K_valid_HR\")\n",
        "\n",
        "# Check if dataset folders exist\n",
        "if not os.path.exists(DIV2K_train_HR):\n",
        "    raise FileNotFoundError(f\"Training folder not found: {DIV2K_train_HR}\")\n",
        "if not os.path.exists(DIV2K_valid_HR):\n",
        "    print(f\"Validation folder not found: {DIV2K_valid_HR}, proceeding with training data split.\")\n",
        "print(\"Paths are set correctly!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Loading and preparing the data\n",
        "Download and process DIV2K dataset"
      ],
      "metadata": {
        "id": "v0VNgCkNFB1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images\n",
        "def load_images(path, target_size=(256, 256)):\n",
        "    images = []\n",
        "    for filename in os.listdir(path):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            img = load_img(os.path.join(path, filename), target_size=target_size)\n",
        "            img = img_to_array(img) / 255.0  # Normalize images to [0, 1]\n",
        "            images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Function to downscale images\n",
        "def downscale_images(images, scale=2):\n",
        "    LR_images = []\n",
        "    for img in images:\n",
        "        h, w, _ = img.shape\n",
        "        LR = cv2.resize(img, (w // scale, h // scale), interpolation=cv2.INTER_AREA)\n",
        "        LR_images.append(LR)\n",
        "    return np.array(LR_images)\n",
        "\n",
        "# Load HR training images\n",
        "HR_images_train = load_images(DIV2K_train_HR)\n",
        "LR_images_train = downscale_images(HR_images_train)\n",
        "\n",
        "# Load HR validation images if available, otherwise split training data\n",
        "if os.path.exists(DIV2K_valid_HR):\n",
        "    HR_images_valid = load_images(DIV2K_valid_HR)\n",
        "    LR_images_valid = downscale_images(HR_images_valid)\n",
        "else:\n",
        "    HR_images_train, HR_images_valid = train_test_split(HR_images_train, test_size=0.2, random_state=42)\n",
        "    LR_images_train, LR_images_valid = train_test_split(LR_images_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply data augmentation to training data\n",
        "datagen = ImageDataGenerator(rotation_range=15, horizontal_flip=True, vertical_flip=True)\n",
        "batch_size = 32\n",
        "HR_augmented = datagen.flow(HR_images_train, batch_size=batch_size, shuffle=True)\n",
        "LR_augmented = datagen.flow(LR_images_train, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "-_IvAQ-I78BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Building the Super-Resolution model"
      ],
      "metadata": {
        "id": "xTTbV0VD5rN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load VGG16 model once (outside the perceptual_loss function)\n",
        "vgg = VGG16(include_top=False, weights='imagenet', input_shape=(None, None, 3))\n",
        "vgg.trainable = False  # Freeze VGG16 layers\n",
        "feature_extractor = tf.keras.Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
        "\n",
        "# Define perceptual loss function\n",
        "def perceptual_loss(y_true, y_pred):\n",
        "    true_features = feature_extractor(y_true)\n",
        "    pred_features = feature_extractor(y_pred)\n",
        "    return tf.reduce_mean(tf.square(true_features - pred_features))\n",
        "\n",
        "# Function to create an improved Super-Resolution model\n",
        "def build_improved_model():\n",
        "    inputs = Input(shape=(None, None, 3))\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    for _ in range(5):  # Add 5 residual blocks\n",
        "        residual = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "        residual = Conv2D(64, (3, 3), activation='relu', padding='same')(residual)\n",
        "        x = Add()([x, residual])  # Add residual connection\n",
        "    x = UpSampling2D(size=(2, 2))(x)  # Upsample the output\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    outputs = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss=perceptual_loss)\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "model = build_improved_model()\n",
        "model.summary()  # Display the model architecture\n",
        "\n"
      ],
      "metadata": {
        "id": "pxTVeV-FtNnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training the model"
      ],
      "metadata": {
        "id": "pAX0-vo15zaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation sets\n",
        "LR_train, LR_val, HR_train, HR_val = train_test_split(LR_images_train, HR_images_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define callbacks for training\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss')\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    LR_train, HR_train,\n",
        "    validation_data=(LR_val, HR_val),\n",
        "    batch_size=batch_size,\n",
        "    epochs=15,\n",
        "    callbacks=callbacks,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Model Training Progress')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Si-vMEhR54_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Testing the model\n",
        "Compare results with cv2.resize"
      ],
      "metadata": {
        "id": "pwYw0Y3q6Khw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to upscale an image using the trained model\n",
        "def upscale_image(model, LR_image):\n",
        "    LR_image = np.expand_dims(LR_image, axis=0)  # Add batch dimension\n",
        "    SR_image = model.predict(LR_image)[0]  # Predict and remove batch dimension\n",
        "    SR_image = np.clip(SR_image * 255.0, 0, 255).astype('uint8')  # Denormalize\n",
        "    return SR_image\n",
        "\n",
        "# Function to display results\n",
        "def display_results(LR, SR, HR, Interpolated):\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
        "    axes[0].imshow(LR)\n",
        "    axes[0].set_title(\"Low Resolution\")\n",
        "    axes[1].imshow(Interpolated)\n",
        "    axes[1].set_title(\"Interpolation (Cubic)\")\n",
        "    axes[2].imshow(SR)\n",
        "    axes[2].set_title(\"Super Resolution\")\n",
        "    axes[3].imshow(HR)\n",
        "    axes[3].set_title(\"High Resolution\")\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Test on a random validation sample\n",
        "index = np.random.randint(len(LR_val))\n",
        "LR_sample = LR_val[index]\n",
        "HR_sample = HR_val[index]\n",
        "\n",
        "# Super-Resolution using the trained model\n",
        "SR_sample = upscale_image(model, LR_sample)\n",
        "\n",
        "# Traditional interpolation (cv2.resize)\n",
        "interpolated_sample = cv2.resize(\n",
        "    LR_sample, (HR_sample.shape[1], HR_sample.shape[0]), interpolation=cv2.INTER_CUBIC\n",
        ")\n",
        "\n",
        "# Display the results\n",
        "display_results(LR_sample, SR_sample, HR_sample, interpolated_sample)\n"
      ],
      "metadata": {
        "id": "kTfppFN0Xyyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oEn6cnOHZmCM"
      }
    }
  ]
}